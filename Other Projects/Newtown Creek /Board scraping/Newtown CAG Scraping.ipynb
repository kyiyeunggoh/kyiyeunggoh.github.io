{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "##obtain pdf file lists\n",
    "import os\n",
    "pdfnames=[]\n",
    "for file in os.listdir('/Users/pyeungyeung/Desktop/Columbia/Spring 19/Points Unknown/scrape'):\n",
    "    if file.endswith(\".pdf\"):\n",
    "        pdfnames.append(\"scrape/\" +os.path.join(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getnames(meeting_file):\n",
    "    resource_mgr = PDFResourceManager()\n",
    "    retstr = BytesIO()\n",
    "    codec = 'utf-8'\n",
    "    laparams = LAParams()\n",
    "    device = TextConverter(resource_mgr, retstr, laparams=laparams)\n",
    "    fp = open(meeting_file, 'rb')\n",
    "    interpreter = PDFPageInterpreter(resource_mgr, device)\n",
    "    maxpages = 0\n",
    "    caching = True\n",
    "    pagenos = set()\n",
    "    for page in PDFPage.get_pages(fp, pagenos,\n",
    "                              maxpages=maxpages,\n",
    "                              caching=caching,\n",
    "                              check_extractable=True):\n",
    "        interpreter.process_page(page)\n",
    "    return (retstr.getvalue())\n",
    "    type(retstr.getvalue())\n",
    "\n",
    "    fp.close()\n",
    "    device.close()\n",
    "    retstr.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicts =[]\n",
    "keys = pdfnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(keys)):\n",
    "        dictelem = getnames(keys[i])\n",
    "        dicts.append(dictelem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfdict=dict(zip(pdfnames, dicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "OUTPUT_FILE = './newtown_minutes.json'\n",
    "json.dump(pdfdict,open(OUTPUT_FILE, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import math\n",
    "from itertools import product\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from nltk.tokenize import TreebankWordTokenizer, RegexpTokenizer, TweetTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "mins=json.load(open('newtown_minutes.json','r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist=[]\n",
    "for key in mins.keys():\n",
    "    mylist.append(mins[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stemmer=PorterStemmer()\n",
    "bagofwords1=[]\n",
    "for i in range(len(mylist)):\n",
    "        toclean=(mylist[i])\n",
    "        toclean=re.sub(r'[^\\w\\s]',' ',toclean)\n",
    "        cleaned=re.sub(\"[^a-zA-Z]\", \" \", toclean)\n",
    "        shortword = re.compile(r'\\W*\\b\\w{1,3}\\b')\n",
    "        cleaner=shortword.sub('', cleaned)\n",
    "        tokenwords=TreebankWordTokenizer().tokenize(cleaner)\n",
    "        cleanedstring=' '.join(stemmer.stem(token) for token in tokenwords)\n",
    "        words=cleanedstring.split()\n",
    "        bagofwords1.append(words)\n",
    "        \n",
    "list1=bagofwords1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(list1)):\n",
    "    list1[i]=map(str, list1[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeJobTFDict(jobpost):\n",
    "\n",
    "    jobTFDict = {}\n",
    "    for word in jobpost:\n",
    "        if word in jobTFDict:\n",
    "            jobTFDict[word] += 1\n",
    "        else:\n",
    "            jobTFDict[word] = 1          \n",
    "    for word in jobTFDict:\n",
    "        jobTFDict[word] = jobTFDict[word] / len(jobpost)\n",
    "    return jobTFDict\n",
    "\n",
    "tfdict=[]\n",
    "for i in range(len(list1)):\n",
    "    tfwords=computeJobTFDict(list1[i])\n",
    "    tfdict.append(tfwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computecount():\n",
    "    countwords = {}\n",
    "    for meeting in list1:\n",
    "        for word in meeting:\n",
    "            if word in countwords:\n",
    "                countwords[word] += 1\n",
    "            else:\n",
    "                countwords[word] = 1\n",
    "    return countwords\n",
    "\n",
    "countwords=computecount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countIDF():\n",
    "    idfDict = {}\n",
    "    for word in countwords:\n",
    "        idfDict[word] = math.log(len(list1) / countwords[word])\n",
    "    return idfDict\n",
    "  \n",
    "idfDict = countIDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getTFIDF(meetings):\n",
    "\n",
    "    posttfidf = {}\n",
    "    for word in meetings:\n",
    "        posttfidf[word] = meetings[word] * idfDict[word]\n",
    "    return posttfidf\n",
    "\n",
    "meetingstfidf = [getTFIDF(meetings) for meetings in tfdict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "meetingstfidf=pd.DataFrame(meetingstfidf).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 20 words discussed in meetings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>interview</th>\n",
       "      <td>0.055756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rosemari</th>\n",
       "      <td>0.051752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candid</th>\n",
       "      <td>0.050544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lisa</th>\n",
       "      <td>0.046048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>select</th>\n",
       "      <td>0.045696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bloodgood</th>\n",
       "      <td>0.045394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macdonald</th>\n",
       "      <td>0.043255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ltcp</th>\n",
       "      <td>0.043096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host</th>\n",
       "      <td>0.040382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>endors</th>\n",
       "      <td>0.039778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hurrican</th>\n",
       "      <td>0.039762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>debrief</th>\n",
       "      <td>0.039719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hold</th>\n",
       "      <td>0.037546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skype</th>\n",
       "      <td>0.037173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feel</th>\n",
       "      <td>0.036475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frustrat</th>\n",
       "      <td>0.036435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>posit</th>\n",
       "      <td>0.036021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sandi</th>\n",
       "      <td>0.035916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sever</th>\n",
       "      <td>0.035846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>option</th>\n",
       "      <td>0.035002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              words\n",
       "interview  0.055756\n",
       "rosemari   0.051752\n",
       "candid     0.050544\n",
       "lisa       0.046048\n",
       "select     0.045696\n",
       "bloodgood  0.045394\n",
       "macdonald  0.043255\n",
       "ltcp       0.043096\n",
       "host       0.040382\n",
       "endors     0.039778\n",
       "hurrican   0.039762\n",
       "debrief    0.039719\n",
       "hold       0.037546\n",
       "skype      0.037173\n",
       "feel       0.036475\n",
       "frustrat   0.036435\n",
       "posit      0.036021\n",
       "sandi      0.035916\n",
       "sever      0.035846\n",
       "option     0.035002"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top20=pd.DataFrame(meetingstfidf.sum(axis=0))\n",
    "top20.columns=[\"words\"]\n",
    "top20.sort_values('words',ascending =False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern by years: 2012 to 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfnames=[]\n",
    "for file in os.listdir('/Users/pyeungyeung/Desktop/Columbia/Spring 19/Points Unknown/scrape 1/2012'):\n",
    "    if file.endswith(\".pdf\"):\n",
    "        pdfnames.append(\"scrape 1/2012/\" + os.path.join(file))\n",
    "        \n",
    "def getnames(meeting_file):\n",
    "    resource_mgr = PDFResourceManager()\n",
    "    retstr = BytesIO()\n",
    "    codec = 'utf-8'\n",
    "    laparams = LAParams()\n",
    "    device = TextConverter(resource_mgr, retstr, laparams=laparams)\n",
    "    fp = open(meeting_file, 'rb')\n",
    "    interpreter = PDFPageInterpreter(resource_mgr, device)\n",
    "    maxpages = 0\n",
    "    caching = True\n",
    "    pagenos = set()\n",
    "    for page in PDFPage.get_pages(fp, pagenos,\n",
    "                              maxpages=maxpages,\n",
    "                              caching=caching,\n",
    "                              check_extractable=True):\n",
    "        interpreter.process_page(page)\n",
    "    return (retstr.getvalue())\n",
    "    type(retstr.getvalue())\n",
    "\n",
    "    fp.close()\n",
    "    device.close()\n",
    "    retstr.close()\n",
    "\n",
    "dicts =[]\n",
    "keys = pdfnames\n",
    "\n",
    "for i in range(len(keys)):\n",
    "        dictelem = getnames(keys[i])\n",
    "        dicts.append(dictelem)\n",
    "\n",
    "pdfdict=dict(zip(pdfnames, dicts))\n",
    "OUTPUT_FILE = './newtown_minutes2012.json'\n",
    "json.dump(pdfdict,open(OUTPUT_FILE, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfnames=[]\n",
    "for file in os.listdir('/Users/pyeungyeung/Desktop/Columbia/Spring 19/Points Unknown/scrape 1/2013'):\n",
    "    if file.endswith(\".pdf\"):\n",
    "        pdfnames.append(\"scrape 1/2013/\" + os.path.join(file))\n",
    "        \n",
    "def getnames(meeting_file):\n",
    "    resource_mgr = PDFResourceManager()\n",
    "    retstr = BytesIO()\n",
    "    codec = 'utf-8'\n",
    "    laparams = LAParams()\n",
    "    device = TextConverter(resource_mgr, retstr, laparams=laparams)\n",
    "    fp = open(meeting_file, 'rb')\n",
    "    interpreter = PDFPageInterpreter(resource_mgr, device)\n",
    "    maxpages = 0\n",
    "    caching = True\n",
    "    pagenos = set()\n",
    "    for page in PDFPage.get_pages(fp, pagenos,\n",
    "                              maxpages=maxpages,\n",
    "                              caching=caching,\n",
    "                              check_extractable=True):\n",
    "        interpreter.process_page(page)\n",
    "    return (retstr.getvalue())\n",
    "    type(retstr.getvalue())\n",
    "\n",
    "    fp.close()\n",
    "    device.close()\n",
    "    retstr.close()\n",
    "\n",
    "dicts =[]\n",
    "keys = pdfnames\n",
    "\n",
    "for i in range(len(keys)):\n",
    "        dictelem = getnames(keys[i])\n",
    "        dicts.append(dictelem)\n",
    "\n",
    "pdfdict=dict(zip(pdfnames, dicts))\n",
    "OUTPUT_FILE = './newtown_minutes2013.json'\n",
    "json.dump(pdfdict,open(OUTPUT_FILE, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfnames=[]\n",
    "for file in os.listdir('/Users/pyeungyeung/Desktop/Columbia/Spring 19/Points Unknown/scrape 1/2014'):\n",
    "    if file.endswith(\".pdf\"):\n",
    "        pdfnames.append(\"scrape 1/2014/\" + os.path.join(file))\n",
    "        \n",
    "def getnames(meeting_file):\n",
    "    resource_mgr = PDFResourceManager()\n",
    "    retstr = BytesIO()\n",
    "    codec = 'utf-8'\n",
    "    laparams = LAParams()\n",
    "    device = TextConverter(resource_mgr, retstr, laparams=laparams)\n",
    "    fp = open(meeting_file, 'rb')\n",
    "    interpreter = PDFPageInterpreter(resource_mgr, device)\n",
    "    maxpages = 0\n",
    "    caching = True\n",
    "    pagenos = set()\n",
    "    for page in PDFPage.get_pages(fp, pagenos,\n",
    "                              maxpages=maxpages,\n",
    "                              caching=caching,\n",
    "                              check_extractable=True):\n",
    "        interpreter.process_page(page)\n",
    "    return (retstr.getvalue())\n",
    "    type(retstr.getvalue())\n",
    "\n",
    "    fp.close()\n",
    "    device.close()\n",
    "    retstr.close()\n",
    "\n",
    "dicts =[]\n",
    "keys = pdfnames\n",
    "\n",
    "for i in range(len(keys)):\n",
    "        dictelem = getnames(keys[i])\n",
    "        dicts.append(dictelem)\n",
    "\n",
    "pdfdict=dict(zip(pdfnames, dicts))\n",
    "OUTPUT_FILE = './newtown_minutes2014.json'\n",
    "json.dump(pdfdict,open(OUTPUT_FILE, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfnames=[]\n",
    "for file in os.listdir('/Users/pyeungyeung/Desktop/Columbia/Spring 19/Points Unknown/scrape 1/2015'):\n",
    "    if file.endswith(\".pdf\"):\n",
    "        pdfnames.append(\"scrape 1/2015/\" + os.path.join(file))\n",
    "        \n",
    "def getnames(meeting_file):\n",
    "    resource_mgr = PDFResourceManager()\n",
    "    retstr = BytesIO()\n",
    "    codec = 'utf-8'\n",
    "    laparams = LAParams()\n",
    "    device = TextConverter(resource_mgr, retstr, laparams=laparams)\n",
    "    fp = open(meeting_file, 'rb')\n",
    "    interpreter = PDFPageInterpreter(resource_mgr, device)\n",
    "    maxpages = 0\n",
    "    caching = True\n",
    "    pagenos = set()\n",
    "    for page in PDFPage.get_pages(fp, pagenos,\n",
    "                              maxpages=maxpages,\n",
    "                              caching=caching,\n",
    "                              check_extractable=True):\n",
    "        interpreter.process_page(page)\n",
    "    return (retstr.getvalue())\n",
    "    type(retstr.getvalue())\n",
    "\n",
    "    fp.close()\n",
    "    device.close()\n",
    "    retstr.close()\n",
    "\n",
    "dicts =[]\n",
    "keys = pdfnames\n",
    "\n",
    "for i in range(len(keys)):\n",
    "        dictelem = getnames(keys[i])\n",
    "        dicts.append(dictelem)\n",
    "\n",
    "pdfdict=dict(zip(pdfnames, dicts))\n",
    "OUTPUT_FILE = './newtown_minutes2015.json'\n",
    "json.dump(pdfdict,open(OUTPUT_FILE, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfnames=[]\n",
    "for file in os.listdir('/Users/pyeungyeung/Desktop/Columbia/Spring 19/Points Unknown/scrape 1/2016'):\n",
    "    if file.endswith(\".pdf\"):\n",
    "        pdfnames.append(\"scrape 1/2016/\" + os.path.join(file))\n",
    "        \n",
    "def getnames(meeting_file):\n",
    "    resource_mgr = PDFResourceManager()\n",
    "    retstr = BytesIO()\n",
    "    codec = 'utf-8'\n",
    "    laparams = LAParams()\n",
    "    device = TextConverter(resource_mgr, retstr, laparams=laparams)\n",
    "    fp = open(meeting_file, 'rb')\n",
    "    interpreter = PDFPageInterpreter(resource_mgr, device)\n",
    "    maxpages = 0\n",
    "    caching = True\n",
    "    pagenos = set()\n",
    "    for page in PDFPage.get_pages(fp, pagenos,\n",
    "                              maxpages=maxpages,\n",
    "                              caching=caching,\n",
    "                              check_extractable=True):\n",
    "        interpreter.process_page(page)\n",
    "    return (retstr.getvalue())\n",
    "    type(retstr.getvalue())\n",
    "\n",
    "    fp.close()\n",
    "    device.close()\n",
    "    retstr.close()\n",
    "\n",
    "dicts =[]\n",
    "keys = pdfnames\n",
    "\n",
    "for i in range(len(keys)):\n",
    "        dictelem = getnames(keys[i])\n",
    "        dicts.append(dictelem)\n",
    "\n",
    "pdfdict=dict(zip(pdfnames, dicts))\n",
    "OUTPUT_FILE = './newtown_minutes2016.json'\n",
    "json.dump(pdfdict,open(OUTPUT_FILE, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfnames=[]\n",
    "for file in os.listdir('/Users/pyeungyeung/Desktop/Columbia/Spring 19/Points Unknown/scrape 1/2017'):\n",
    "    if file.endswith(\".pdf\"):\n",
    "        pdfnames.append(\"scrape 1/2017/\" + os.path.join(file))\n",
    "        \n",
    "def getnames(meeting_file):\n",
    "    resource_mgr = PDFResourceManager()\n",
    "    retstr = BytesIO()\n",
    "    codec = 'utf-8'\n",
    "    laparams = LAParams()\n",
    "    device = TextConverter(resource_mgr, retstr, laparams=laparams)\n",
    "    fp = open(meeting_file, 'rb')\n",
    "    interpreter = PDFPageInterpreter(resource_mgr, device)\n",
    "    maxpages = 0\n",
    "    caching = True\n",
    "    pagenos = set()\n",
    "    for page in PDFPage.get_pages(fp, pagenos,\n",
    "                              maxpages=maxpages,\n",
    "                              caching=caching,\n",
    "                              check_extractable=True):\n",
    "        interpreter.process_page(page)\n",
    "    return (retstr.getvalue())\n",
    "    type(retstr.getvalue())\n",
    "\n",
    "    fp.close()\n",
    "    device.close()\n",
    "    retstr.close()\n",
    "\n",
    "dicts =[]\n",
    "keys = pdfnames\n",
    "\n",
    "for i in range(len(keys)):\n",
    "        dictelem = getnames(keys[i])\n",
    "        dicts.append(dictelem)\n",
    "\n",
    "pdfdict=dict(zip(pdfnames, dicts))\n",
    "OUTPUT_FILE = './newtown_minutes2017.json'\n",
    "json.dump(pdfdict,open(OUTPUT_FILE, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfnames=[]\n",
    "for file in os.listdir('/Users/pyeungyeung/Desktop/Columbia/Spring 19/Points Unknown/scrape 1/2018'):\n",
    "    if file.endswith(\".pdf\"):\n",
    "        pdfnames.append(\"scrape 1/2018/\" + os.path.join(file))\n",
    "        \n",
    "def getnames(meeting_file):\n",
    "    resource_mgr = PDFResourceManager()\n",
    "    retstr = BytesIO()\n",
    "    codec = 'utf-8'\n",
    "    laparams = LAParams()\n",
    "    device = TextConverter(resource_mgr, retstr, laparams=laparams)\n",
    "    fp = open(meeting_file, 'rb')\n",
    "    interpreter = PDFPageInterpreter(resource_mgr, device)\n",
    "    maxpages = 0\n",
    "    caching = True\n",
    "    pagenos = set()\n",
    "    for page in PDFPage.get_pages(fp, pagenos,\n",
    "                              maxpages=maxpages,\n",
    "                              caching=caching,\n",
    "                              check_extractable=True):\n",
    "        interpreter.process_page(page)\n",
    "    return (retstr.getvalue())\n",
    "    type(retstr.getvalue())\n",
    "\n",
    "    fp.close()\n",
    "    device.close()\n",
    "    retstr.close()\n",
    "\n",
    "dicts =[]\n",
    "keys = pdfnames\n",
    "\n",
    "for i in range(len(keys)):\n",
    "        dictelem = getnames(keys[i])\n",
    "        dicts.append(dictelem)\n",
    "\n",
    "pdfdict=dict(zip(pdfnames, dicts))\n",
    "OUTPUT_FILE = './newtown_minutes2018.json'\n",
    "json.dump(pdfdict,open(OUTPUT_FILE, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gettop20df(jsonfile):\n",
    "    mins=json.load(open(jsonfile,'r'))\n",
    "    mylist=[]\n",
    "    for key in mins.keys():\n",
    "        mylist.append(mins[key])\n",
    "\n",
    "    bagofwords1=[]\n",
    "    for i in range(len(mylist)):\n",
    "            toclean=(mylist[i])\n",
    "            toclean=re.sub(r'[^\\w\\s]',' ',toclean)\n",
    "            cleaned=re.sub(\"[^a-zA-Z]\", \" \", toclean)\n",
    "            shortword = re.compile(r'\\W*\\b\\w{1,3}\\b')\n",
    "            cleaner=shortword.sub('', cleaned)\n",
    "            tokenwords=TreebankWordTokenizer().tokenize(cleaner)\n",
    "            cleanedstring=' '.join(stemmer.stem(token) for token in tokenwords)\n",
    "            words=cleanedstring.split()\n",
    "            bagofwords1.append(words)\n",
    "        \n",
    "    list1=bagofwords1\n",
    "\n",
    "    for i in range(len(list1)):\n",
    "        list1[i]=map(str, list1[i])\n",
    "    \n",
    "    tfdict=[]\n",
    "    for i in range(len(list1)):\n",
    "        tfwords=computeJobTFDict(list1[i])\n",
    "        tfdict.append(tfwords)\n",
    "    \n",
    "    countwords=computecount()\n",
    "    idfDict = countIDF()\n",
    "    meetingstfidf = [getTFIDF(meetings) for meetings in tfdict]\n",
    "    meetingstfidf=pd.DataFrame(meetingstfidf).fillna(0)\n",
    "    top20=pd.DataFrame(meetingstfidf.sum(axis=0))\n",
    "    top20.columns=[\"words\"]\n",
    "    top20=top20.sort_values('words',ascending =False).head(20)\n",
    "    return top20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top words for 2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cuni</th>\n",
       "      <td>0.026799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>osrti</th>\n",
       "      <td>0.025219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enviro</th>\n",
       "      <td>0.025219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hurrican</th>\n",
       "      <td>0.023556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crisi</th>\n",
       "      <td>0.022085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>immedi</th>\n",
       "      <td>0.022085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zidar</th>\n",
       "      <td>0.021671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>termin</th>\n",
       "      <td>0.021654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metro</th>\n",
       "      <td>0.021654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ncmc</th>\n",
       "      <td>0.021139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kate</th>\n",
       "      <td>0.021078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raphael</th>\n",
       "      <td>0.019998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gwapp</th>\n",
       "      <td>0.019982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coleman</th>\n",
       "      <td>0.019730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heimbind</th>\n",
       "      <td>0.019730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brian</th>\n",
       "      <td>0.019730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>erik</th>\n",
       "      <td>0.019730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pend</th>\n",
       "      <td>0.019730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baard</th>\n",
       "      <td>0.019730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>solut</th>\n",
       "      <td>0.019582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             words\n",
       "cuni      0.026799\n",
       "osrti     0.025219\n",
       "enviro    0.025219\n",
       "hurrican  0.023556\n",
       "crisi     0.022085\n",
       "immedi    0.022085\n",
       "zidar     0.021671\n",
       "termin    0.021654\n",
       "metro     0.021654\n",
       "ncmc      0.021139\n",
       "kate      0.021078\n",
       "raphael   0.019998\n",
       "gwapp     0.019982\n",
       "coleman   0.019730\n",
       "heimbind  0.019730\n",
       "brian     0.019730\n",
       "erik      0.019730\n",
       "pend      0.019730\n",
       "baard     0.019730\n",
       "solut     0.019582"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gettop20df('newtown_minutes2012.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top words for 2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alic</th>\n",
       "      <td>0.025112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forum</th>\n",
       "      <td>0.023275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speaker</th>\n",
       "      <td>0.022204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moder</th>\n",
       "      <td>0.021737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sandi</th>\n",
       "      <td>0.018751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>usepa</th>\n",
       "      <td>0.018751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nomin</th>\n",
       "      <td>0.018356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hurrican</th>\n",
       "      <td>0.016206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>secur</th>\n",
       "      <td>0.015520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>osha</th>\n",
       "      <td>0.015194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roll</th>\n",
       "      <td>0.015064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>serv</th>\n",
       "      <td>0.014877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baker</th>\n",
       "      <td>0.014525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>posit</th>\n",
       "      <td>0.014009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accord</th>\n",
       "      <td>0.013288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emerg</th>\n",
       "      <td>0.013179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mayor</th>\n",
       "      <td>0.012858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>effect</th>\n",
       "      <td>0.012688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aerat</th>\n",
       "      <td>0.012577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transit</th>\n",
       "      <td>0.012511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             words\n",
       "alic      0.025112\n",
       "forum     0.023275\n",
       "speaker   0.022204\n",
       "moder     0.021737\n",
       "sandi     0.018751\n",
       "usepa     0.018751\n",
       "nomin     0.018356\n",
       "hurrican  0.016206\n",
       "secur     0.015520\n",
       "osha      0.015194\n",
       "roll      0.015064\n",
       "serv      0.014877\n",
       "baker     0.014525\n",
       "posit     0.014009\n",
       "accord    0.013288\n",
       "emerg     0.013179\n",
       "mayor     0.012858\n",
       "effect    0.012688\n",
       "aerat     0.012577\n",
       "transit   0.012511"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gettop20df('newtown_minutes2013.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tour</th>\n",
       "      <td>0.015391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expert</th>\n",
       "      <td>0.013645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cag</th>\n",
       "      <td>0.012308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gate</th>\n",
       "      <td>0.011037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tide</th>\n",
       "      <td>0.009955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>passaic</th>\n",
       "      <td>0.009955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resili</th>\n",
       "      <td>0.009878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>panel</th>\n",
       "      <td>0.009597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drive</th>\n",
       "      <td>0.009597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>river</th>\n",
       "      <td>0.009521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>winter</th>\n",
       "      <td>0.009412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>devot</th>\n",
       "      <td>0.008618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>observ</th>\n",
       "      <td>0.008495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jersey</th>\n",
       "      <td>0.008201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>island</th>\n",
       "      <td>0.008163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>explan</th>\n",
       "      <td>0.007945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kirbi</th>\n",
       "      <td>0.007826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>webster</th>\n",
       "      <td>0.007826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>signag</th>\n",
       "      <td>0.007677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>green</th>\n",
       "      <td>0.007584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            words\n",
       "tour     0.015391\n",
       "expert   0.013645\n",
       "cag      0.012308\n",
       "gate     0.011037\n",
       "tide     0.009955\n",
       "passaic  0.009955\n",
       "resili   0.009878\n",
       "panel    0.009597\n",
       "drive    0.009597\n",
       "river    0.009521\n",
       "winter   0.009412\n",
       "devot    0.008618\n",
       "observ   0.008495\n",
       "jersey   0.008201\n",
       "island   0.008163\n",
       "explan   0.007945\n",
       "kirbi    0.007826\n",
       "webster  0.007826\n",
       "signag   0.007677\n",
       "green    0.007584"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gettop20df('newtown_minutes2014.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cstag</th>\n",
       "      <td>0.023281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spill</th>\n",
       "      <td>0.015742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seem</th>\n",
       "      <td>0.014417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>statement</th>\n",
       "      <td>0.014330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>followup</th>\n",
       "      <td>0.014087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>say</th>\n",
       "      <td>0.013484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lilli</th>\n",
       "      <td>0.013183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aren</th>\n",
       "      <td>0.012118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>outsid</th>\n",
       "      <td>0.012030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hour</th>\n",
       "      <td>0.011225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>randi</th>\n",
       "      <td>0.011178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>onenyc</th>\n",
       "      <td>0.011178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>austin</th>\n",
       "      <td>0.011178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exercis</th>\n",
       "      <td>0.011014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.011014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>solid</th>\n",
       "      <td>0.010759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>face</th>\n",
       "      <td>0.010442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hand</th>\n",
       "      <td>0.010383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breakout</th>\n",
       "      <td>0.010383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>show</th>\n",
       "      <td>0.009975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              words\n",
       "cstag      0.023281\n",
       "spill      0.015742\n",
       "seem       0.014417\n",
       "statement  0.014330\n",
       "followup   0.014087\n",
       "say        0.013484\n",
       "lilli      0.013183\n",
       "aren       0.012118\n",
       "outsid     0.012030\n",
       "hour       0.011225\n",
       "randi      0.011178\n",
       "onenyc     0.011178\n",
       "austin     0.011178\n",
       "exercis    0.011014\n",
       "count      0.011014\n",
       "solid      0.010759\n",
       "face       0.010442\n",
       "hand       0.010383\n",
       "breakout   0.010383\n",
       "show       0.009975"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gettop20df('newtown_minutes2015.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anchor</th>\n",
       "      <td>0.023218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ebullit</th>\n",
       "      <td>0.021884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>foia</th>\n",
       "      <td>0.018995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>groundwat</th>\n",
       "      <td>0.018775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nrda</th>\n",
       "      <td>0.017485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ltcp</th>\n",
       "      <td>0.016934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>judith</th>\n",
       "      <td>0.016357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sure</th>\n",
       "      <td>0.015555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boguski</th>\n",
       "      <td>0.015552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>found</th>\n",
       "      <td>0.015428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>station</th>\n",
       "      <td>0.014410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rainfal</th>\n",
       "      <td>0.014350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crab</th>\n",
       "      <td>0.014165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>solheim</th>\n",
       "      <td>0.013695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feedback</th>\n",
       "      <td>0.013679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deborah</th>\n",
       "      <td>0.013489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>principl</th>\n",
       "      <td>0.013406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enck</th>\n",
       "      <td>0.013398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scenario</th>\n",
       "      <td>0.013318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>languag</th>\n",
       "      <td>0.013102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              words\n",
       "anchor     0.023218\n",
       "ebullit    0.021884\n",
       "foia       0.018995\n",
       "groundwat  0.018775\n",
       "nrda       0.017485\n",
       "ltcp       0.016934\n",
       "judith     0.016357\n",
       "sure       0.015555\n",
       "boguski    0.015552\n",
       "found      0.015428\n",
       "station    0.014410\n",
       "rainfal    0.014350\n",
       "crab       0.014165\n",
       "solheim    0.013695\n",
       "feedback   0.013679\n",
       "deborah    0.013489\n",
       "principl   0.013406\n",
       "enck       0.013398\n",
       "scenario   0.013318\n",
       "languag    0.013102"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gettop20df('newtown_minutes2016.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
